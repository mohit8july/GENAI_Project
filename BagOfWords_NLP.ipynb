{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JMWRbgKtruXU"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line imports the CountVectorizer class from the feature_extraction.text module of the scikit-learn library. CountVectorizer is a technique to convert text data into a numerical format which is required for machine learning models\n"
      ],
      "metadata": {
        "id": "DoSVFMQVsIxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\"the quick brown fox\", \"jumped over the lazy dog\"]"
      ],
      "metadata": {
        "id": "Wu7lnJUSsBh_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define a Python list named documents, which contains two strings. Each string is considered as a separate document. In a real-world scenario, these could be two different paragraphs, emails, or any other collection of text"
      ],
      "metadata": {
        "id": "ZEHf09VfsO2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()"
      ],
      "metadata": {
        "id": "PxiSh9aRsNK3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line initializes an instance of the CountVectorizer class and assigns it to the variable vectorizer. This object will be configured to perform tokenization and count occurrences of tokens (words) in the documents."
      ],
      "metadata": {
        "id": "Y3pa_1XZsSlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_matrix = vectorizer.fit_transform(documents)"
      ],
      "metadata": {
        "id": "KFqrMAXVsQvi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fit_transform method is called on the vectorizer object with our documents list as the argument. What this does is:\n",
        "fit part: learns the vocabulary of the entire text corpus (in this case, the two documents combined).\n",
        "transform part: transforms the text documents into a sparse matrix where each row corresponds to a document and each column corresponds to a term (word) in the learned vocabulary. The values in the matrix represent the frequency count of each term in each document"
      ],
      "metadata": {
        "id": "RRLI5D3UsfSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9KiR7wLsduz",
        "outputId": "4f5df33e-df14-4226-cf9a-fc3894da1a49"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['brown' 'dog' 'fox' 'jumped' 'lazy' 'over' 'quick' 'the']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After fitting the model to the data, get_feature_names_out() is called to get the list of feature names, which in this case are the words extracted from the documents. This will print out the vocabulary that the vectorizer has learned from the input documents"
      ],
      "metadata": {
        "id": "RYj7S8CMsnto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(bow_matrix.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi-e_HiXsmDy",
        "outputId": "20489576-5db5-4142-9a2f-a02e4136ea8f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0 1 0 0 0 1 1]\n",
            " [0 1 0 1 1 1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, toarray() is called on the bow_matrix object to convert the sparse matrix into a regular (dense) NumPy array for easy viewing. The resulting array is printed out, and each row of the array corresponds to one of the documents, with the columns representing the word counts of the respective terms in the vocabulary"
      ],
      "metadata": {
        "id": "2MdtN3m1srv-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nc6zdds3sp2L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}